{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b06c258-b397-43a2-80f8-2f2c8624c951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9456bf-4501-49ef-8fab-a88af13079b6",
   "metadata": {},
   "source": [
    "### 6. Wrangle the data in preparation for machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3f814d-7249-405a-a5b6-5a1a3226d369",
   "metadata": {},
   "source": [
    "rubric={correctness:20}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8fca0d-6196-4d0f-afa2-a0b929a9b946",
   "metadata": {},
   "source": [
    "Our data currently covers all of NSW, but say that our client wants us to create a machine learning model to predict rainfall over Sydney only. There's a bit of wrangling that needs to be done for that:\n",
    "1. We need to query our data for only the rows that contain information covering Sydney\n",
    "2. We need to wrangle our data into a format suitable for training a machine learning model. That will require pivoting, resampling, grouping, etc.\n",
    "\n",
    "To train an ML algorithm we need it to look like this:\n",
    "\n",
    "||model-1_rainfall|model-2_rainfall|model-3_rainfall|...|observed_rainfall|\n",
    "|---|---|---|---|---|---|\n",
    "|0|0.12|0.43|0.35|...|0.31|\n",
    "|1|1.22|0.91|1.68|...|1.34|\n",
    "|2|0.68|0.29|0.41|...|0.57|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9805a39-c3d0-48b4-97e7-7e6901d6e609",
   "metadata": {},
   "source": [
    "6.1) Get the data from s3 (```combined_model_data_parti.parquet``` and ```observed_daily_rainfall_SYD.csv```)\n",
    "\n",
    "6.2) First query for Sydney data and then drop the lat and lon columns (we don't need them).\n",
    "```\n",
    "syd_lat = -33.86\n",
    "syd_lon = 151.21\n",
    "```\n",
    "Expected shape ```(1150049, 2)```.\n",
    "\n",
    "6.3) Save this processed file to s3 for later use:\n",
    "\n",
    "  Save as a csv file ```ml_data_SYD.csv``` to ```s3://mds-s3-xxx/output/```\n",
    "  expected shape ```(46020,26)``` - This includes all the models as columns and also adding additional column ```Observed``` loaded from ```observed_daily_rainfall_SYD.csv``` from s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d6ec480-162f-4f23-b167-8693dba90f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do all your coding here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e24aa64-7c34-4449-a840-b8b142a2ca65",
   "metadata": {},
   "source": [
    "The following cell is for the local folder to store the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bda0d04a-961e-41e6-9130-e87cffdd0177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Users/stevenprivate/mds/525/web_and_cloud_group_1/data # This is the local folder to store the CSV file.'\n",
      "/Users/stevenprivate/mds/525/web_and_cloud_group_1/data\n"
     ]
    }
   ],
   "source": [
    "%cd ~/mds/525/web_and_cloud_group_1/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ca5051-c33c-4668-aa62-edb889bf4264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    text  number\n",
      "0   this       2\n",
      "1     is       3\n",
      "2      a       4\n",
      "3  dummy       5\n",
      "4    csv       6\n",
      "5   file       7\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dummy.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ff073-e822-4ca0-9ec9-2e11274fe9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "df = pd.read_parquet('s3://testmds/combined_data_partition.big10.parquet',filters=[[('year','=', 2002),('Origin', '=', 'ORD'),('Dest','=','PHL'),('DepDelay','>',10)]], columns=['UniqueCarrier', 'DepDelay'])\n",
    "print(df.groupby('UniqueCarrier').mean('DepDelay'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525_2022]",
   "language": "python",
   "name": "conda-env-525_2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
